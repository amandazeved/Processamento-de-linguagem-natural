{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xLNX2yrHdfV"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from gensim import utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection          import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI_0Ve2I-g9A"
      },
      "source": [
        "Nesta atividade você irá exercitar o que aprendeu sobre Word Embeddings na disciplina nas seguintes tarefas:\n",
        "- treinamento de um word embedding em dados jurídicos e avaliação do mesmo em tarefas de similaridade e analogia;\n",
        "- treinamento de um word embedding em dados de comentários de produtos da Amazon e aplicá-los para classificação de sentimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QesG4ukQ_9jg"
      },
      "source": [
        "# 1. Treinando um word embedding com word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poCcy7MbABPH"
      },
      "source": [
        "Nesta tarefa iremos criar nossos próprios word embeddings. Para isso usaremos dados que são documentos jurídicos coletados da plataforma Jusbrasil.\n",
        "\n",
        "Para criar nossos embeddings usaremos a classe `Word2Vec` da biblioteca `gensim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVMqZJrLAr2x",
        "outputId": "3b3cccbc-ff41-4cc9-b66e-199329637bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-29 18:22:42--  https://raw.githubusercontent.com/issilva5/oclsnippets/master/teor_judiciario.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39955780 (38M) [text/plain]\n",
            "Saving to: ‘teor_inteiro_jusbrasil.txt’\n",
            "\n",
            "teor_inteiro_jusbra 100%[===================>]  38.10M   204MB/s    in 0.2s    \n",
            "\n",
            "2023-09-29 18:22:42 (204 MB/s) - ‘teor_inteiro_jusbrasil.txt’ saved [39955780/39955780]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/issilva5/oclsnippets/master/teor_judiciario.txt -O teor_inteiro_jusbrasil.txt\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mrFoIZiAvxE"
      },
      "source": [
        "Essa classe recebe em sua inicialização alguns parâmetros importantes:\n",
        " - *corpus_file*: o caminho para um arquivo em que cada documento está contido em uma linha.\n",
        " - *vector_size*: o tamanho do vetor de embedding a ser gerado.\n",
        " - *window_size*: o tamanho da janela a ser considerada no modelo ao buscar por palavras vizinhas.\n",
        "\n",
        "\n",
        " Para a atividade você deve explorar **cinco** valores diferentes para pelo menos um desses parâmetros. Isto é, por exemplo, você pode decidir usar vector_size = 50 e testar variar o window_size entre 1 e 5. Ou window_size = 4 e variar o vector_size em [25, 50, 100, 200, 300]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjxe0-NMChw-"
      },
      "outputs": [],
      "source": [
        "# Na lista abaixo insira as configurações que você escolheu para testar\n",
        "# na forma (vector_size, window_size)\n",
        "combinacoes = [\n",
        "    (50,5),\n",
        "    (100,5),\n",
        "    (200,5),\n",
        "    (300,5),\n",
        "    (400,5),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQu3Owu-CCUy"
      },
      "source": [
        "Treinaremos então nossos modelos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnlTRuzJA8l_"
      },
      "outputs": [],
      "source": [
        "modelos = [Word2Vec(corpus_file='teor_inteiro_jusbrasil.txt', window = ws, vector_size = vs).wv for vs, ws in combinacoes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNFHCPOjE8RZ"
      },
      "source": [
        "Com os modelos treinados acima, você deve responder as seguintes perguntas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shwHggLKFBW4"
      },
      "source": [
        "## 1.1 Quais as top-5 palavras mais similares a juiz? Como elas variam considerando as diferentes configurações? Você acha que elas fazem sentido?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxsl9hxIFQLn",
        "outputId": "6f6bdfcc-775e-47aa-9a0b-cf5102b8ef40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo 0 - vector_size = 50, window_size = 5\n",
            "[('juíza', 0.7285166382789612),\n",
            " ('desembargador', 0.7235047221183777),\n",
            " ('(juiz', 0.683124840259552),\n",
            " ('magistrado', 0.6386556625366211),\n",
            " ('julgador', 0.622808575630188)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 1 - vector_size = 100, window_size = 5\n",
            "[('juíza', 0.6705533266067505),\n",
            " ('magistrado', 0.6647987365722656),\n",
            " ('desembargador', 0.6407379508018494),\n",
            " ('(juiz', 0.621371328830719),\n",
            " ('juiz,', 0.580100953578949)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 2 - vector_size = 200, window_size = 5\n",
            "[('juíza', 0.673319399356842),\n",
            " ('magistrado', 0.6658952832221985),\n",
            " ('desembargador', 0.6235745549201965),\n",
            " ('(juiz', 0.5969828963279724),\n",
            " ('julgador', 0.5568087697029114)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 3 - vector_size = 300, window_size = 5\n",
            "[('juíza', 0.672717273235321),\n",
            " ('magistrado', 0.6553894281387329),\n",
            " ('desembargador', 0.6244509816169739),\n",
            " ('(juiz', 0.6077473759651184),\n",
            " ('juiz,', 0.564876914024353)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 4 - vector_size = 400, window_size = 5\n",
            "[('juíza', 0.6679136157035828),\n",
            " ('magistrado', 0.6529962420463562),\n",
            " ('desembargador', 0.6225771903991699),\n",
            " ('(juiz', 0.587215781211853),\n",
            " ('juiz,', 0.5579310059547424)]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, modelo in enumerate(modelos):\n",
        "  print(f'Modelo {i} - vector_size = {combinacoes[i][0]}, window_size = {combinacoes[i][1]}')\n",
        "  # Insira aqui o cálculo das palavras mais similares\n",
        "  # Dica para uma melhor visualização utilize pprint ao invés de print\n",
        "  top5 = modelo.most_similar(positive=['juiz'], topn=5)\n",
        "  pprint(top5)\n",
        "  print('-'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKnyogmuF7-t"
      },
      "source": [
        "Nos 5 modelos a palavras foram iguais, mas a ordem foi diferente. Podemos perceber que o valor de similaridade caiu um pouco com relação ao menor valor de vector_size, isso acontece pois estamos aumentando a dimensão do espaço vetorial de cada palavra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5708bXQGKZ3"
      },
      "source": [
        "## 1.2 Responda a analogia promotora está para juiz como promotor está para o que? Houve diferença nas respostas considerando os diferentes modelos? Qual deu a melhor resposta?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WccPyDlvGhq5",
        "outputId": "d0f9ffba-21ef-4b7d-f6b8-0b01fc7a6e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo 0 - vector_size = 50, window_size = 5\n",
            "[('juíza', 0.7319112420082092), ('declinar', 0.6709084510803223)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 1 - vector_size = 100, window_size = 5\n",
            "[('juíza', 0.7099308967590332), ('remetente', 0.5649728178977966)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 2 - vector_size = 200, window_size = 5\n",
            "[('juíza', 0.678337037563324), ('magistrado', 0.5087990164756775)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 3 - vector_size = 300, window_size = 5\n",
            "[('juíza', 0.6888377070426941), ('economica', 0.5222272872924805)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 4 - vector_size = 400, window_size = 5\n",
            "[('juíza', 0.6978282928466797), ('juíza:', 0.5627674460411072)]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, modelo in enumerate(modelos):\n",
        "  print(f'Modelo {i} - vector_size = {combinacoes[i][0]}, window_size = {combinacoes[i][1]}')\n",
        "  # Insira aqui o cálculo da analogia\n",
        "  # Dica para uma melhor visualização utilize pprint ao invés de print\n",
        "  word = modelo.most_similar(positive=['juiz','promotora'], negative=['promotor'], topn=2)\n",
        "  pprint(word)\n",
        "  print('-'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOZS46YoGmGF"
      },
      "source": [
        "A resposta deu igual para os todos modelos: 'juíza'. Mas os modelos apresentaram diferenças na segunda palavra onde só o modelo com um numero mais alto no vector_size resultou em uma palavra quase igual a primeira."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boAfn9exGtGq"
      },
      "source": [
        "## 1.3 A variação do parâmetro escolhido impactou na qualidade dos modelos gerados? Porquê você acha que esse parâmetro impactou (ou não) a qualidade dos modelos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIdidkndH1yd"
      },
      "source": [
        "Não percebi um impacto significativo nos modelos ao variar o vector_size, pois todos eles compartilham o mesmo conjunto de palavras no top 5 de palavras mais similares a 'juiz'. O que podemos notar são apenas pequenas variações nos valores de similaridade entre os modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1zbw4bsIXM5"
      },
      "source": [
        "## 1.4 Utilize o modelo que você julgar como o melhor para encontrar um caso de palavra em que as palavras mais similares não fazem muito sentido. Por que você acha que o modelo não foi bem neste caso?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbuxKJV5IihL",
        "outputId": "9922b623-f49d-4c32-815e-5ac19ba0b2f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('tutela,', 0.7926527261734009),\n",
            " ('liminar', 0.7720767855644226),\n",
            " ('antecipação', 0.7619683742523193),\n",
            " ('urgência', 0.7516860365867615),\n",
            " ('urgência,', 0.7032164335250854)]\n"
          ]
        }
      ],
      "source": [
        "# Insira aqui o código\n",
        "pprint(modelos[1].most_similar(positive=['tutela'], topn=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsmcD_fNIk06"
      },
      "source": [
        "O modelo identificou 4 palavras bastante distintas em relação à palavra-alvo 'tutela'. Acredito que esse resultado tenha ocorrido devido a palavra 'tutela' poder ser empregada em mais de um contexto, podendo ser usar no sentido de proteção e assistência a um indivíduo ou a responsabilidade sobre algo, como por exemplo, administrar os bens de um menor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPUHxDawIyYB"
      },
      "source": [
        "# 2. Usando word embeddings para classificação de sentimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkAjtbt7_pNX"
      },
      "source": [
        "É possível utilizar word embeddings para classificação de sentimentos através de modelos de linguagem, porém nesta atividade exploraremos uma forma mais simples de usar word embeddings para esta tarefa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7xGVNagJLfa"
      },
      "source": [
        "Primeiramente, execute a célula seguinte para gerar o dataset. Os dados que serão utilizados são comentários em produtos no site Amazon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2YSqQOn_oiq",
        "outputId": "6487ea7c-2ac2-4f93-b0a3-6dc8e5e9b86e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-29 21:03:53--  https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_neg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 315761 (308K) [text/plain]\n",
            "Saving to: ‘books_pt_neg’\n",
            "\n",
            "\rbooks_pt_neg          0%[                    ]       0  --.-KB/s               \rbooks_pt_neg        100%[===================>] 308.36K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-09-29 21:03:53 (9.93 MB/s) - ‘books_pt_neg’ saved [315761/315761]\n",
            "\n",
            "--2023-09-29 21:03:53--  https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_pos\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 430160 (420K) [text/plain]\n",
            "Saving to: ‘books_pt_pos’\n",
            "\n",
            "books_pt_pos        100%[===================>] 420.08K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-09-29 21:03:53 (11.1 MB/s) - ‘books_pt_pos’ saved [430160/430160]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_neg -O books_pt_neg\n",
        "!wget https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_pos -O books_pt_pos\n",
        "\n",
        "corpus_neg = []\n",
        "corpus_pos = []\n",
        "\n",
        "for line in open('books_pt_neg'):\n",
        "  corpus_neg.append(utils.simple_preprocess(line))\n",
        "\n",
        "for line in open('books_pt_pos'):\n",
        "  corpus_pos.append(utils.simple_preprocess(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Bb471UJ7Lx"
      },
      "source": [
        "A variável *corpus_neg* contém os comentários negativos, enquanto a variável *corpus_pos* contém os comentários positivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf5H4RhVJ507",
        "outputId": "f06f54c8-d760-4620-f3c5-db54c222d9fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['concordo',\n",
              " 'com',\n",
              " 'outras',\n",
              " 'avaliações',\n",
              " 'feitas',\n",
              " 'entre',\n",
              " 'outros',\n",
              " 'sobre',\n",
              " 'diálogos',\n",
              " 'fracos',\n",
              " 'infantis',\n",
              " 'acrescento',\n",
              " 'que',\n",
              " 'li',\n",
              " 'em',\n",
              " 'avaliações',\n",
              " 'de',\n",
              " 'outros',\n",
              " 'ebooks',\n",
              " 'em',\n",
              " 'português',\n",
              " 'linguagem',\n",
              " 'está',\n",
              " 'pra',\n",
              " 'lá',\n",
              " 'de',\n",
              " 'apelativa',\n",
              " 'repetitiva',\n",
              " 'nada',\n",
              " 'atraente',\n",
              " 'muito',\n",
              " 'menos',\n",
              " 'romântica',\n",
              " 'perdeu',\n",
              " 'se',\n",
              " 'totalmente',\n",
              " 'noção',\n",
              " 'não',\n",
              " 'há',\n",
              " 'qualquer',\n",
              " 'critério',\n",
              " 'de',\n",
              " 'edição',\n",
              " 'tentando',\n",
              " 'agora',\n",
              " 'os',\n",
              " 'em',\n",
              " 'inglês',\n",
              " 'para',\n",
              " 'ver',\n",
              " 'se',\n",
              " 'tem',\n",
              " 'algo',\n",
              " 'melhor']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_neg[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph3bcqbzJ0o5",
        "outputId": "8360ef4e-cb9c-4e0b-96fe-c134f2a7d9ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['enfim',\n",
              " 'final',\n",
              " 'da',\n",
              " 'série',\n",
              " 'chegou',\n",
              " 'me',\n",
              " 'deixou',\n",
              " 'arrebatada',\n",
              " 'emocionada',\n",
              " 'um',\n",
              " 'final',\n",
              " 'cheio',\n",
              " 'de',\n",
              " 'amor',\n",
              " 'lembranças',\n",
              " 'perfeito',\n",
              " 'para',\n",
              " 'uma',\n",
              " 'série',\n",
              " 'tão',\n",
              " 'emocionante',\n",
              " 'intensa',\n",
              " 'mauricio',\n",
              " 'era',\n",
              " 'último',\n",
              " 'dos',\n",
              " 'lafaietes',\n",
              " 'solteiro',\n",
              " 'mas',\n",
              " 'eleonora',\n",
              " 'arrebatou',\n",
              " 'seu',\n",
              " 'coração',\n",
              " 'ainda',\n",
              " 'que',\n",
              " 'não',\n",
              " 'estivesse',\n",
              " 'nos',\n",
              " 'seus',\n",
              " 'planos',\n",
              " 'ele',\n",
              " 'desde',\n",
              " 'sempre',\n",
              " 'soube',\n",
              " 'que',\n",
              " 'queria',\n",
              " 'correu',\n",
              " 'atrás',\n",
              " 'para',\n",
              " 'realizar',\n",
              " 'os',\n",
              " 'seus',\n",
              " 'sonhos',\n",
              " 'eleonora',\n",
              " 'não',\n",
              " 'foi',\n",
              " 'uma',\n",
              " 'mocinha',\n",
              " 'fácil',\n",
              " 'dócil',\n",
              " 'maumau',\n",
              " 'ao',\n",
              " 'contrário',\n",
              " 'decidido',\n",
              " 'intenso',\n",
              " 'apaixonado',\n",
              " 'uma',\n",
              " 'história',\n",
              " 'cativante',\n",
              " 'que',\n",
              " 'vai',\n",
              " 'te',\n",
              " 'envolvendo',\n",
              " 'amor',\n",
              " 'não',\n",
              " 'tem',\n",
              " 'idade',\n",
              " 'não',\n",
              " 'vê',\n",
              " 'traumas',\n",
              " 'preconceitos',\n",
              " 'ele',\n",
              " 'vai',\n",
              " 'arrebatando',\n",
              " 'tudo',\n",
              " 'supera',\n",
              " 'foi',\n",
              " 'exatamente',\n",
              " 'isso',\n",
              " 'que',\n",
              " 'autora',\n",
              " 'foi',\n",
              " 'nos',\n",
              " 'revelando',\n",
              " 'aos',\n",
              " 'poucos',\n",
              " 'uma',\n",
              " 'história',\n",
              " 'de',\n",
              " 'superação',\n",
              " 'perdão',\n",
              " 'aceitação',\n",
              " 'um',\n",
              " 'final',\n",
              " 'repleto',\n",
              " 'de',\n",
              " 'figuras',\n",
              " 'queridas',\n",
              " 'cheio',\n",
              " 'de',\n",
              " 'lágrimas',\n",
              " 'emoção',\n",
              " 'estou',\n",
              " 'definitivamente',\n",
              " 'de',\n",
              " 'ressaca',\n",
              " 'literária',\n",
              " 'os',\n",
              " 'lafaietes',\n",
              " 'sempre',\n",
              " 'terão',\n",
              " 'um',\n",
              " 'pedacinho',\n",
              " 'do',\n",
              " 'meu',\n",
              " 'coração',\n",
              " 'super',\n",
              " 'recomendo']"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_pos[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re8v0aWQKh0U"
      },
      "source": [
        "Agora para treinar nossos modelos precisamos obter uma representação de cada sentença como um vetor de features, que chamaremos de *sentence embedding*. Nesta atividade iremos gerar os sentence embedding através da média dos word embeddings das palavras que compõem cada sentença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb9WWNitKw4d"
      },
      "source": [
        "Primeiramente, crie um novo modelo Word2Vec usando ambos os conjuntos de sentenças, com parâmetros a sua escolha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyWBMEQg-OAn"
      },
      "outputs": [],
      "source": [
        "# Além dos parâmetros que discutimos acima, inclua o parâmetro min_count=1\n",
        "corpus = corpus_neg + corpus_pos\n",
        "modelo = Word2Vec(sentences=corpus, window = 5, vector_size = 100, min_count=1).wv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhcPByloLg08"
      },
      "source": [
        "Agora vamos criar uma função que dada uma sentença e um modelo Word2Vec retorna o *sentence embedding* dessa sentença. Para calcular a média dos vetores você pode utilizar a função `np.mean`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SvkK_eeLgG3"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embedding(sentence, model):\n",
        "  embeddings = [model[word] for word in sentence if word in model]\n",
        "  return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upvXwvgpMVn3"
      },
      "source": [
        "A seguir você deve aplicar a função sobre os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt8egts0MhFI"
      },
      "outputs": [],
      "source": [
        "# Calcule a lista com os embeddings das sentenças negativas\n",
        "sentences_embeddings_neg = []\n",
        "for sentence in corpus_neg:\n",
        "  if len(sentence) > 0:\n",
        "    sentences_embeddings_neg.append(get_sentence_embedding(sentence, modelo))\n",
        "\n",
        "# Calcule a lista com os embeddings das sentenças positivas\n",
        "sentences_embeddings_pos = []\n",
        "for sentence in corpus_pos:\n",
        "  if len(sentence) > 0:\n",
        "    sentences_embeddings_pos.append(get_sentence_embedding(sentence, modelo))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVoOy62zNwN8"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate([sentences_embeddings_neg, sentences_embeddings_pos])\n",
        "y = np.concatenate([[-1]*len(sentences_embeddings_neg), [1]*len(sentences_embeddings_pos)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXgf5CeINssB"
      },
      "source": [
        "Crie uma partição treino e teste usando a função `train_test_split` do sklearn, usando as variáveis X e y acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0VCccVZOFOm"
      },
      "outputs": [],
      "source": [
        "# Crie a partição treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VELbINQYOINH"
      },
      "source": [
        "## 2.1 Agora instancie pelo menos dois modelos de classificação, em seguida os treine e avalie na sua partição. Discuta os resultados em termos das métricas previamentes vistas em sala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW250gAiOZie",
        "outputId": "be265185-d860-4d78-a320-0f748a0add58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia da Regressão Logística: 0.5453895639742673 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.54      0.58      0.56       696\n",
            "           1       0.55      0.51      0.53       703\n",
            "\n",
            "    accuracy                           0.55      1399\n",
            "   macro avg       0.55      0.55      0.55      1399\n",
            "weighted avg       0.55      0.55      0.54      1399\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Treinamento e avaliação do modelo 1\n",
        "from sklearn.linear_model import LogisticRegression , Perceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model_rl = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "\n",
        "y_pred_rl = model_rl.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_rl)\n",
        "\n",
        "print(\"Acurácia da Regressão Logística:\", accuracy, \"\\n\")\n",
        "print(classification_report(y_test, y_pred_rl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu9QzOC_OcPi",
        "outputId": "64c966c5-3dd7-4525-e1a4-495850c4c80c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia do Percerptron: 0.505360972122945 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.83      0.01      0.01       696\n",
            "           1       0.50      1.00      0.67       703\n",
            "\n",
            "    accuracy                           0.51      1399\n",
            "   macro avg       0.67      0.50      0.34      1399\n",
            "weighted avg       0.67      0.51      0.34      1399\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Treinamento e avaliação do modelo 2\n",
        "\n",
        "model_p = Perceptron().fit(X_train, y_train)\n",
        "\n",
        "y_pred_p = model_p.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_p)\n",
        "\n",
        "print(\"Acurácia do Percerptron:\", accuracy, \"\\n\")\n",
        "print(classification_report(y_test, y_pred_p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8KfnyzCOecr"
      },
      "source": [
        "A média de acurácia dos dois modelos foi baixa, aproximadamente 50%, indicando uma taxa de acertos nas previsões inferior. Isso também é refletido na métrica de previsões, recall e f1-score. No entanto, vale ressaltar que o modelo Perceptron obteve um desempenho ligeiramente superior ao da Regressão Logística."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
